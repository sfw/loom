"""Interactive first-run setup wizard for Loom.

Walks users through configuring their first model provider and writes
~/.loom/loom.toml.  Re-enterable via ``loom setup`` at any time.
"""

from __future__ import annotations

import sys
from pathlib import Path

import click

# Provider presets: (display_name, provider_key, needs_api_key, default_base_url)
PROVIDERS = [
    ("Anthropic (Claude API)", "anthropic", True, "https://api.anthropic.com"),
    ("OpenAI-compatible server", "openai_compatible", False, "http://localhost:1234/v1"),
    ("Ollama", "ollama", False, "http://localhost:11434"),
]

ANTHROPIC_MODELS = [
    "claude-sonnet-4-5-20250929",
    "claude-opus-4-20250115",
    "claude-haiku-4-5-20251001",
]

ROLE_PRESETS = {
    "all": ["planner", "executor", "extractor", "verifier"],
    "primary": ["planner", "executor"],
    "utility": ["extractor", "verifier"],
}

CONFIG_DIR = Path.home() / ".loom"
CONFIG_PATH = CONFIG_DIR / "loom.toml"


def needs_setup() -> bool:
    """Return True if no user config exists yet."""
    if CONFIG_PATH.exists():
        return False
    # Also check cwd for a project-local config
    if (Path.cwd() / "loom.toml").exists():
        return False
    return True


def _prompt_provider() -> tuple[str, str, bool, str]:
    """Ask which provider to use.  Returns (display, key, needs_key, default_url)."""
    click.echo()
    click.echo("Which model provider will you use?")
    click.echo()
    for i, (display, _key, _needs, _url) in enumerate(PROVIDERS, 1):
        click.echo(f"  {i}. {display}")
    click.echo()

    choice = click.prompt(
        "Provider",
        type=click.IntRange(1, len(PROVIDERS)),
        default=1,
    )
    return PROVIDERS[choice - 1]


def _prompt_anthropic_model() -> tuple[str, str, str]:
    """Collect Anthropic-specific settings.  Returns (base_url, model, api_key)."""
    click.echo()
    click.echo("Available Claude models:")
    click.echo()
    for i, m in enumerate(ANTHROPIC_MODELS, 1):
        click.echo(f"  {i}. {m}")
    click.echo()
    choice = click.prompt(
        "Model",
        type=click.IntRange(1, len(ANTHROPIC_MODELS)),
        default=1,
    )
    model = ANTHROPIC_MODELS[choice - 1]

    api_key = click.prompt(
        "Anthropic API key",
        hide_input=True,
    )
    if not api_key.strip():
        click.echo("API key is required for Anthropic.", err=True)
        sys.exit(1)

    base_url = click.prompt(
        "Base URL (press Enter for default)",
        default="https://api.anthropic.com",
        show_default=True,
    )
    return base_url, model, api_key.strip()


def _prompt_openai_model(default_url: str) -> tuple[str, str, str]:
    """Collect OpenAI-compatible settings.  Returns (base_url, model, api_key)."""
    click.echo()
    base_url = click.prompt(
        "Server URL",
        default=default_url,
        show_default=True,
    )
    model = click.prompt("Model name (e.g. gpt-4o, mistral-nemo, etc.)")
    api_key = ""
    if click.confirm("Does this server require an API key?", default=False):
        api_key = click.prompt("API key", hide_input=True).strip()
    return base_url, model, api_key


def _prompt_ollama_model(default_url: str) -> tuple[str, str, str]:
    """Collect Ollama settings.  Returns (base_url, model, api_key)."""
    click.echo()
    base_url = click.prompt(
        "Ollama URL",
        default=default_url,
        show_default=True,
    )
    model = click.prompt(
        "Model name (e.g. qwen3:14b, llama3:8b, etc.)",
    )
    return base_url, model, ""


def _prompt_roles() -> list[str]:
    """Ask which roles this model should fill."""
    click.echo()
    click.echo("Which roles should this model handle?")
    click.echo()
    click.echo("  1. All roles (planner, executor, extractor, verifier)")
    click.echo("  2. Primary (planner, executor)")
    click.echo("  3. Utility (extractor, verifier)")
    click.echo()
    choice = click.prompt(
        "Roles", type=click.IntRange(1, 3), default=1,
    )
    presets = ["all", "primary", "utility"]
    return ROLE_PRESETS[presets[choice - 1]]


def _generate_toml(models: list[dict]) -> str:
    """Generate a loom.toml string from collected model configs."""
    lines = [
        "# Loom configuration",
        "# Generated by `loom setup` — edit freely.",
        "",
        "[server]",
        'host = "127.0.0.1"',
        "port = 9000",
        "",
    ]

    for m in models:
        lines.append(f"[models.{m['name']}]")
        lines.append(f'provider = "{m["provider"]}"')
        if m.get("base_url"):
            lines.append(f'base_url = "{m["base_url"]}"')
        lines.append(f'model = "{m["model"]}"')
        if m.get("api_key"):
            lines.append(f'api_key = "{m["api_key"]}"')
        lines.append(f"max_tokens = {m.get('max_tokens', 4096)}")
        lines.append(f"temperature = {m.get('temperature', 0.1)}")
        roles_str = ", ".join(f'"{r}"' for r in m["roles"])
        lines.append(f"roles = [{roles_str}]")
        lines.append("")

    lines.extend([
        "[workspace]",
        'default_path = "~/projects"',
        'scratch_dir = "~/.loom/scratch"',
        "",
        "[execution]",
        "max_subtask_retries = 3",
        "max_loop_iterations = 50",
        "auto_approve_confidence_threshold = 0.8",
        "",
        "[verification]",
        "tier1_enabled = true",
        "tier2_enabled = true",
        "tier3_enabled = false",
        "tier3_vote_count = 3",
        "",
        "[memory]",
        'database_path = "~/.loom/loom.db"',
        "",
        "[logging]",
        'level = "INFO"',
        'event_log_path = "~/.loom/logs"',
        "",
    ])
    return "\n".join(lines)


def run_setup(*, reconfigure: bool = False) -> Path:
    """Run the interactive setup wizard.

    Args:
        reconfigure: If True, allow overwriting an existing config.

    Returns:
        Path to the written config file.
    """
    click.echo()
    click.secho("  Loom Setup", bold=True)
    click.echo("  " + "─" * 40)
    click.echo()

    if CONFIG_PATH.exists() and not reconfigure:
        click.echo(f"  Config already exists: {CONFIG_PATH}")
        if not click.confirm("  Overwrite with new configuration?", default=False):
            click.echo("  Setup cancelled.")
            sys.exit(0)

    # -- Collect primary model -------------------------------------------------
    click.secho("  Primary model", bold=True)
    click.echo("  This model handles planning and task execution.")

    display, provider_key, needs_key, default_url = _prompt_provider()

    if provider_key == "anthropic":
        base_url, model, api_key = _prompt_anthropic_model()
    elif provider_key == "openai_compatible":
        base_url, model, api_key = _prompt_openai_model(default_url)
    else:
        base_url, model, api_key = _prompt_ollama_model(default_url)

    roles = _prompt_roles()

    models = [{
        "name": "primary",
        "provider": provider_key,
        "base_url": base_url,
        "model": model,
        "api_key": api_key,
        "roles": roles,
        "max_tokens": 4096,
        "temperature": 0.1,
    }]

    # -- Optional utility model ------------------------------------------------
    # Only offer if primary doesn't cover all roles
    missing = set(ROLE_PRESETS["all"]) - set(roles)
    if missing:
        click.echo()
        missing_str = ", ".join(sorted(missing))
        click.echo(f"  Uncovered roles: {missing_str}")
        if click.confirm("  Add a second model for those roles?", default=False):
            click.echo()
            click.secho("  Utility model", bold=True)

            _, u_provider, _, u_default_url = _prompt_provider()

            if u_provider == "anthropic":
                u_base, u_model, u_key = _prompt_anthropic_model()
            elif u_provider == "openai_compatible":
                u_base, u_model, u_key = _prompt_openai_model(u_default_url)
            else:
                u_base, u_model, u_key = _prompt_ollama_model(u_default_url)

            models.append({
                "name": "utility",
                "provider": u_provider,
                "base_url": u_base,
                "model": u_model,
                "api_key": u_key,
                "roles": sorted(missing),
                "max_tokens": 2048,
                "temperature": 0.0,
            })

    # -- Write config ----------------------------------------------------------
    toml_content = _generate_toml(models)

    click.echo()
    click.echo("  Configuration preview:")
    click.echo("  " + "─" * 40)
    for line in toml_content.splitlines():
        click.echo(f"  {line}")
    click.echo("  " + "─" * 40)
    click.echo()

    if not click.confirm(f"  Write to {CONFIG_PATH}?", default=True):
        click.echo("  Setup cancelled.")
        sys.exit(0)

    CONFIG_DIR.mkdir(parents=True, exist_ok=True)
    CONFIG_PATH.write_text(toml_content)

    # Ensure supporting directories exist
    (CONFIG_DIR / "scratch").mkdir(parents=True, exist_ok=True)
    (CONFIG_DIR / "logs").mkdir(parents=True, exist_ok=True)
    (CONFIG_DIR / "processes").mkdir(parents=True, exist_ok=True)

    click.echo()
    click.secho("  Setup complete!", bold=True)
    click.echo(f"  Config written to {CONFIG_PATH}")
    click.echo("  Run `loom` to start, or `loom setup` to reconfigure.")
    click.echo()

    return CONFIG_PATH
