<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Loom Tutorial - Local Model Orchestration Engine</title>
<style>
  :root {
    --bg: #0f1117;
    --bg-card: #161822;
    --bg-code: #1c1e2e;
    --border: #2a2d3e;
    --text: #e2e4f0;
    --text-dim: #8b8fa3;
    --accent: #7c6ff7;
    --accent-glow: rgba(124, 111, 247, 0.15);
    --green: #4ade80;
    --yellow: #fbbf24;
    --red: #f87171;
    --cyan: #22d3ee;
    --mono: 'SF Mono', 'Cascadia Code', 'Fira Code', 'JetBrains Mono', Consolas, monospace;
    --sans: -apple-system, BlinkMacSystemFont, 'Segoe UI', Inter, Roboto, sans-serif;
  }

  * { margin: 0; padding: 0; box-sizing: border-box; }

  body {
    background: var(--bg);
    color: var(--text);
    font-family: var(--sans);
    line-height: 1.7;
    font-size: 16px;
  }

  /* --- Navigation --- */
  nav {
    position: fixed;
    top: 0;
    left: 0;
    width: 260px;
    height: 100vh;
    background: var(--bg-card);
    border-right: 1px solid var(--border);
    padding: 24px 0;
    overflow-y: auto;
    z-index: 100;
  }

  nav .logo {
    padding: 0 24px 20px;
    font-size: 22px;
    font-weight: 700;
    letter-spacing: -0.5px;
    color: var(--accent);
    border-bottom: 1px solid var(--border);
    margin-bottom: 16px;
  }

  nav a {
    display: block;
    padding: 8px 24px;
    color: var(--text-dim);
    text-decoration: none;
    font-size: 14px;
    transition: all 0.15s;
    border-left: 3px solid transparent;
  }

  nav a:hover, nav a.active {
    color: var(--text);
    background: var(--accent-glow);
    border-left-color: var(--accent);
  }

  nav .section-label {
    padding: 16px 24px 6px;
    font-size: 11px;
    text-transform: uppercase;
    letter-spacing: 1px;
    color: var(--text-dim);
    font-weight: 600;
  }

  /* --- Main Content --- */
  main {
    margin-left: 260px;
    max-width: 820px;
    padding: 48px 48px 120px;
  }

  section {
    margin-bottom: 64px;
    scroll-margin-top: 24px;
  }

  h1 {
    font-size: 36px;
    font-weight: 800;
    letter-spacing: -1px;
    margin-bottom: 12px;
    background: linear-gradient(135deg, var(--accent), var(--cyan));
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    background-clip: text;
  }

  h2 {
    font-size: 24px;
    font-weight: 700;
    margin-bottom: 16px;
    padding-top: 8px;
    color: var(--text);
  }

  h3 {
    font-size: 18px;
    font-weight: 600;
    margin: 24px 0 12px;
    color: var(--text);
  }

  p { margin-bottom: 16px; color: var(--text); }

  .subtitle {
    font-size: 18px;
    color: var(--text-dim);
    margin-bottom: 40px;
  }

  /* --- Code Blocks --- */
  pre {
    background: var(--bg-code);
    border: 1px solid var(--border);
    border-radius: 8px;
    padding: 20px 24px;
    margin: 16px 0 24px;
    overflow-x: auto;
    font-family: var(--mono);
    font-size: 13.5px;
    line-height: 1.6;
    position: relative;
  }

  pre .label {
    position: absolute;
    top: 8px;
    right: 12px;
    font-size: 11px;
    color: var(--text-dim);
    text-transform: uppercase;
    letter-spacing: 0.5px;
  }

  code {
    font-family: var(--mono);
    font-size: 13.5px;
    background: var(--bg-code);
    padding: 2px 6px;
    border-radius: 4px;
    color: var(--cyan);
  }

  pre code {
    background: none;
    padding: 0;
    color: var(--text);
  }

  .cmd { color: var(--green); }
  .flag { color: var(--yellow); }
  .str { color: var(--cyan); }
  .cmt { color: var(--text-dim); }
  .key { color: var(--accent); }
  .val { color: var(--green); }

  /* --- Cards --- */
  .card {
    background: var(--bg-card);
    border: 1px solid var(--border);
    border-radius: 10px;
    padding: 24px;
    margin: 16px 0;
  }

  .card-grid {
    display: grid;
    grid-template-columns: 1fr 1fr;
    gap: 16px;
    margin: 16px 0;
  }

  .card h4 {
    font-size: 15px;
    font-weight: 600;
    margin-bottom: 8px;
    color: var(--accent);
  }

  .card p { font-size: 14px; margin-bottom: 0; color: var(--text-dim); }

  /* --- Steps --- */
  .step {
    display: flex;
    gap: 20px;
    margin: 24px 0;
    padding: 20px;
    background: var(--bg-card);
    border: 1px solid var(--border);
    border-radius: 10px;
  }

  .step-number {
    flex-shrink: 0;
    width: 36px;
    height: 36px;
    background: var(--accent);
    color: white;
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    font-weight: 700;
    font-size: 15px;
  }

  .step-content { flex: 1; }
  .step-content h4 { font-size: 16px; margin-bottom: 6px; }
  .step-content p { font-size: 14px; color: var(--text-dim); margin-bottom: 8px; }

  /* --- Tables --- */
  table {
    width: 100%;
    border-collapse: collapse;
    margin: 16px 0 24px;
    font-size: 14px;
  }

  th {
    text-align: left;
    padding: 10px 14px;
    background: var(--bg-code);
    border: 1px solid var(--border);
    font-weight: 600;
    color: var(--text-dim);
    font-size: 12px;
    text-transform: uppercase;
    letter-spacing: 0.5px;
  }

  td {
    padding: 10px 14px;
    border: 1px solid var(--border);
    color: var(--text);
  }

  td code { font-size: 12.5px; }

  /* --- Callouts --- */
  .callout {
    padding: 16px 20px;
    border-radius: 8px;
    margin: 16px 0;
    font-size: 14px;
    border-left: 4px solid;
  }

  .callout-info {
    background: rgba(124, 111, 247, 0.08);
    border-color: var(--accent);
  }

  .callout-warn {
    background: rgba(251, 191, 36, 0.08);
    border-color: var(--yellow);
  }

  .callout-success {
    background: rgba(74, 222, 128, 0.08);
    border-color: var(--green);
  }

  .callout strong { display: block; margin-bottom: 4px; }

  /* --- Endpoint Row --- */
  .endpoint {
    display: flex;
    align-items: center;
    gap: 12px;
    padding: 10px 16px;
    background: var(--bg-card);
    border: 1px solid var(--border);
    border-radius: 8px;
    margin: 6px 0;
    font-size: 14px;
  }

  .method {
    font-family: var(--mono);
    font-size: 12px;
    font-weight: 700;
    padding: 2px 8px;
    border-radius: 4px;
    min-width: 60px;
    text-align: center;
  }

  .method-post { background: rgba(74, 222, 128, 0.15); color: var(--green); }
  .method-get { background: rgba(124, 111, 247, 0.15); color: var(--accent); }
  .method-patch { background: rgba(251, 191, 36, 0.15); color: var(--yellow); }
  .method-delete { background: rgba(248, 113, 113, 0.15); color: var(--red); }

  .endpoint-path {
    font-family: var(--mono);
    font-size: 13px;
    color: var(--text);
    flex: 1;
  }

  .endpoint-desc { color: var(--text-dim); font-size: 13px; }

  /* --- Diagram --- */
  .diagram {
    background: var(--bg-code);
    border: 1px solid var(--border);
    border-radius: 10px;
    padding: 32px;
    margin: 24px 0;
    text-align: center;
    font-family: var(--mono);
    font-size: 14px;
    line-height: 1.8;
    color: var(--text-dim);
    overflow-x: auto;
  }

  .diagram .highlight { color: var(--accent); font-weight: 600; }
  .diagram .flow { color: var(--green); }
  .diagram .dim { color: var(--text-dim); }

  /* --- Accordion --- */
  .accordion {
    border: 1px solid var(--border);
    border-radius: 8px;
    margin: 12px 0;
    overflow: hidden;
  }

  .accordion summary {
    padding: 14px 20px;
    background: var(--bg-card);
    cursor: pointer;
    font-weight: 600;
    font-size: 15px;
    list-style: none;
    display: flex;
    align-items: center;
    gap: 8px;
  }

  .accordion summary::before {
    content: '\25B6';
    font-size: 10px;
    transition: transform 0.2s;
    color: var(--text-dim);
  }

  .accordion[open] summary::before { transform: rotate(90deg); }

  .accordion .inner {
    padding: 16px 20px;
    background: var(--bg);
    border-top: 1px solid var(--border);
  }

  /* --- Progress Bar --- */
  .progress-track {
    display: flex;
    gap: 4px;
    margin: 32px 0 16px;
  }

  .progress-step {
    flex: 1;
    height: 4px;
    border-radius: 2px;
    background: var(--border);
  }

  .progress-step.done { background: var(--accent); }

  /* --- Mobile --- */
  @media (max-width: 900px) {
    nav { display: none; }
    main { margin-left: 0; padding: 24px 20px 80px; }
    .card-grid { grid-template-columns: 1fr; }
  }
</style>
</head>
<body>

<!-- Navigation -->
<nav>
  <div class="logo">Loom</div>
  <div class="section-label">Getting Started</div>
  <a href="#intro">Introduction</a>
  <a href="#install">Installation</a>
  <a href="#setup-models">Model Setup</a>
  <a href="#configure">Configuration</a>
  <div class="section-label">Using Loom</div>
  <a href="#start-server">Starting the Server</a>
  <a href="#first-task">Your First Task</a>
  <a href="#streaming">Streaming Events</a>
  <a href="#steering">Steering Tasks</a>
  <a href="#tui">Interactive TUI</a>
  <div class="section-label">Features</div>
  <a href="#processes">Process Definitions</a>
  <a href="#approval">Approval Gates</a>
  <a href="#learning">Adaptive Learning</a>
  <a href="#mcp">MCP Server</a>
  <div class="section-label">API Reference</div>
  <a href="#endpoints">Endpoints</a>
  <a href="#sse">SSE Streaming</a>
  <a href="#memory">Memory System</a>
  <div class="section-label">Advanced</div>
  <a href="#architecture">Architecture</a>
  <a href="#config-ref">Config Reference</a>
  <a href="#troubleshooting">Troubleshooting</a>
</nav>

<!-- Main Content -->
<main>

<!-- ======================== INTRO ======================== -->
<section id="intro">
  <h1>Loom Tutorial</h1>
  <p class="subtitle">Build, run, and monitor tasks with local LLMs -- from installation to production.</p>

  <div class="diagram">
    <span class="highlight">Goal</span> <span class="flow">&rarr;</span> <span class="highlight">Planner</span> <span class="flow">&rarr;</span> <span class="dim">[</span><span class="highlight">Subtask 1</span><span class="dim">]</span> <span class="flow">&rarr;</span> <span class="dim">[</span><span class="highlight">Subtask 2</span><span class="dim">]</span> <span class="flow">&rarr;</span> <span class="dim">...</span> <span class="flow">&rarr;</span> <span class="highlight">Done</span>
    <br>
    <span class="dim">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&darr;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&darr;</span>
    <br>
    <span class="dim">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span>Execute + Verify&nbsp;&nbsp;&nbsp;&nbsp;Execute + Verify
  </div>

  <p>Loom is a <strong>local-first LLM execution harness</strong>. Give it a goal in plain English, and it will:</p>

  <div class="card-grid">
    <div class="card">
      <h4>Decompose</h4>
      <p>Break the goal into ordered subtasks with dependency graphs</p>
    </div>
    <div class="card">
      <h4>Execute</h4>
      <p>Run each subtask in a tool-calling loop (files, shell, search)</p>
    </div>
    <div class="card">
      <h4>Verify</h4>
      <p>Independently check each result against acceptance criteria</p>
    </div>
    <div class="card">
      <h4>Learn</h4>
      <p>Extract decisions and discoveries into structured memory</p>
    </div>
  </div>

  <p>Loom is local-first and can run fully on your machine. It also supports mixed local/cloud setups with <strong>Ollama</strong>, <strong>LM Studio</strong>, <strong>Anthropic/Claude</strong>, or any <strong>OpenAI-compatible API</strong>.</p>
</section>

<!-- ======================== INSTALL ======================== -->
<section id="install">
  <h2>1. Installation</h2>

  <div class="progress-track">
    <div class="progress-step done"></div>
    <div class="progress-step"></div>
    <div class="progress-step"></div>
    <div class="progress-step"></div>
    <div class="progress-step"></div>
  </div>

  <h3>Prerequisites</h3>
  <p>You need <strong>Python 3.11+</strong> and a local model backend.</p>

  <pre><code><span class="cmt"># Check Python version</span>
<span class="cmd">python3</span> <span class="flag">--version</span>
<span class="cmt"># Python 3.11.x or higher required</span></code></pre>

  <h3>Install with uv (Recommended)</h3>
  <pre><code><span class="cmt"># Clone the repository</span>
<span class="cmd">git clone</span> https://github.com/sfw/loom.git
<span class="cmd">cd</span> loom

<span class="cmt"># Install dependencies (creates .venv automatically)</span>
<span class="cmd">uv sync</span>

<span class="cmt"># Include dev tools (pytest, ruff, coverage)</span>
<span class="cmd">uv sync</span> <span class="flag">--extra</span> dev

<span class="cmt"># Verify</span>
<span class="cmd">uv run loom</span> <span class="flag">--version</span>
<span class="cmt"># loom, version 0.1.0</span></code></pre>

  <details class="accordion">
    <summary>Alternative: Install with pip</summary>
    <div class="inner">
      <pre><code><span class="cmd">python3</span> <span class="flag">-m</span> venv .venv
<span class="cmd">source</span> .venv/bin/activate
<span class="cmd">pip install</span> <span class="flag">-e</span> <span class="str">".[dev]"</span>
<span class="cmd">loom</span> <span class="flag">--version</span></code></pre>
    </div>
  </details>

  <div class="callout callout-info">
    <strong>Optional extras</strong>
    Install MCP server support with <code>uv sync --extra mcp</code> or <code>pip install -e ".[mcp]"</code>.
  </div>
</section>

<!-- ======================== SETUP MODELS ======================== -->
<section id="setup-models">
  <h2>2. Model Setup</h2>

  <div class="progress-track">
    <div class="progress-step done"></div>
    <div class="progress-step done"></div>
    <div class="progress-step"></div>
    <div class="progress-step"></div>
    <div class="progress-step"></div>
  </div>

  <p>Loom needs at least one configured LLM backend. Choose your backend:</p>

  <details class="accordion">
    <summary>Ollama (Recommended)</summary>
    <div class="inner">
      <pre><code><span class="cmt"># Install Ollama</span>
<span class="cmd">curl</span> <span class="flag">-fsSL</span> https://ollama.com/install.sh | sh

<span class="cmt"># Pull models</span>
<span class="cmd">ollama pull</span> qwen3:14b      <span class="cmt"># Primary (planning + execution)</span>
<span class="cmd">ollama pull</span> qwen3:8b       <span class="cmt"># Utility (extraction + verification)</span>

<span class="cmt"># Verify it's running</span>
<span class="cmd">curl</span> http://localhost:11434/api/tags</code></pre>
      <p>Ollama runs on port <code>11434</code> by default. Models are downloaded once and cached.</p>
    </div>
  </details>

  <details class="accordion">
    <summary>LM Studio</summary>
    <div class="inner">
      <div class="step">
        <div class="step-number">1</div>
        <div class="step-content">
          <h4>Download LM Studio</h4>
          <p>Get it from <strong>lmstudio.ai</strong></p>
        </div>
      </div>
      <div class="step">
        <div class="step-number">2</div>
        <div class="step-content">
          <h4>Load a Model</h4>
          <p>Search for and download a model (Qwen 2.5, Mistral, Llama, etc.)</p>
        </div>
      </div>
      <div class="step">
        <div class="step-number">3</div>
        <div class="step-content">
          <h4>Start the Server</h4>
          <p>Click "Start Server" in the Local Server tab. Default port: <code>1234</code></p>
        </div>
      </div>
    </div>
  </details>

  <details class="accordion">
    <summary>vLLM / Other OpenAI-Compatible</summary>
    <div class="inner">
      <pre><code><span class="cmt"># Example: vLLM</span>
<span class="cmd">pip install</span> vllm
<span class="cmd">vllm serve</span> Qwen/Qwen2.5-14B-Instruct <span class="flag">--port</span> 8000</code></pre>
      <p>Any server exposing <code>/v1/chat/completions</code> works.</p>
    </div>
  </details>
</section>

<!-- ======================== CONFIGURE ======================== -->
<section id="configure">
  <h2>3. Configuration</h2>

  <div class="progress-track">
    <div class="progress-step done"></div>
    <div class="progress-step done"></div>
    <div class="progress-step done"></div>
    <div class="progress-step"></div>
    <div class="progress-step"></div>
  </div>

  <p>Create <code>loom.toml</code> in your project directory or at <code>~/.loom/loom.toml</code>:</p>

  <pre><code><span class="label">loom.toml</span>
<span class="cmt"># Server settings</span>
<span class="key">[server]</span>
<span class="key">host</span> = <span class="str">"127.0.0.1"</span>
<span class="key">port</span> = <span class="val">9000</span>

<span class="cmt"># Primary model: handles planning and code execution</span>
<span class="key">[models.primary]</span>
<span class="key">provider</span> = <span class="str">"ollama"</span>
<span class="key">base_url</span> = <span class="str">"http://localhost:11434"</span>
<span class="key">model</span>    = <span class="str">"qwen3:14b"</span>
<span class="key">max_tokens</span>   = <span class="val">8192</span>
<span class="key">temperature</span>  = <span class="val">0.1</span>
<span class="key">roles</span> = <span class="str">["planner", "executor"]</span>

<span class="cmt"># Utility model: cheaper/faster for extraction and verification</span>
<span class="key">[models.utility]</span>
<span class="key">provider</span> = <span class="str">"ollama"</span>
<span class="key">base_url</span> = <span class="str">"http://localhost:11434"</span>
<span class="key">model</span>    = <span class="str">"qwen3:8b"</span>
<span class="key">max_tokens</span>   = <span class="val">2048</span>
<span class="key">temperature</span>  = <span class="val">0.0</span>
<span class="key">roles</span> = <span class="str">["extractor", "verifier", "compactor"]</span>

<span class="cmt"># Workspace</span>
<span class="key">[workspace]</span>
<span class="key">default_path</span> = <span class="str">"~/projects"</span>
<span class="key">scratch_dir</span>  = <span class="str">"~/.loom/scratch"</span>

<span class="cmt"># Execution limits</span>
<span class="key">[execution]</span>
<span class="key">max_subtask_retries</span>  = <span class="val">3</span>
<span class="key">max_loop_iterations</span> = <span class="val">50</span>
<span class="key">delegate_task_timeout_seconds</span> = <span class="val">3600</span>

<span class="cmt"># Runner ingest + overflow fallback controls</span>
<span class="key">[limits.runner]</span>
<span class="key">enable_filetype_ingest_router</span> = <span class="val">true</span>
<span class="key">enable_artifact_telemetry_events</span> = <span class="val">true</span>
<span class="key">artifact_telemetry_max_metadata_chars</span> = <span class="val">1200</span>
<span class="key">enable_model_overflow_fallback</span> = <span class="val">true</span>
<span class="key">ingest_artifact_retention_max_age_days</span> = <span class="val">14</span>
<span class="key">ingest_artifact_retention_max_files_per_scope</span> = <span class="val">96</span>
<span class="key">ingest_artifact_retention_max_bytes_per_scope</span> = <span class="val">268435456</span>

<span class="cmt"># Verification gates</span>
<span class="key">[verification]</span>
<span class="key">tier1_enabled</span> = <span class="val">true</span>   <span class="cmt"># Deterministic checks (free, instant)</span>
<span class="key">tier2_enabled</span> = <span class="val">true</span>   <span class="cmt"># Independent LLM verification</span>
<span class="key">tier3_enabled</span> = <span class="val">false</span>  <span class="cmt"># Multi-vote (expensive, off by default)</span>

<span class="cmt"># Memory storage</span>
<span class="key">[memory]</span>
<span class="key">database_path</span> = <span class="str">"~/.loom/loom.db"</span>

<span class="cmt"># MCP servers are managed in ~/.loom/mcp.toml (or ./.loom/mcp.toml)</span></code></pre>

  <pre><code><span class="cmt"># ~/.loom/mcp.toml</span>
<span class="key">[mcp.servers.notion]</span>
<span class="key">command</span> = <span class="str">"npx"</span>
<span class="key">args</span> = <span class="str">["-y", "@modelcontextprotocol/server-notion"]</span>
<span class="key">timeout_seconds</span> = <span class="val">30</span>
<span class="key">enabled</span> = <span class="val">true</span>

<span class="key">[mcp.servers.notion.env]</span>
<span class="key">NOTION_TOKEN</span> = <span class="str">"${NOTION_TOKEN}"</span></code></pre>

  <div class="callout callout-info">
    <strong>External MCP tools</strong>
    Configured MCP servers are auto-discovered and exposed as namespaced tools in Loom (for example <code>mcp.notion.search</code>). Merge precedence is <code>--mcp-config</code> &gt; workspace <code>./.loom/mcp.toml</code> &gt; user <code>~/.loom/mcp.toml</code> &gt; legacy <code>[mcp]</code> in <code>loom.toml</code>.
  </div>

  <pre><code><span class="cmt"># ~/.loom/auth.toml (profile metadata + secret refs; no plaintext secrets)</span>
<span class="key">[auth.defaults]</span>
<span class="key">notion</span> = <span class="str">"notion_marketing"</span>

<span class="key">[auth.profiles.notion_marketing]</span>
<span class="key">provider</span> = <span class="str">"notion"</span>
<span class="key">mode</span> = <span class="str">"oauth2_pkce"</span>
<span class="key">mcp_server</span> = <span class="str">"notion"</span>
<span class="key">token_ref</span> = <span class="str">"keychain://loom/notion/notion_marketing/tokens"</span></code></pre>

  <div class="callout callout-info">
    <strong>Run-start auth resolution</strong>
    Loom resolves auth at run start from process requirements and tool declarations. If one matching profile exists, it is selected automatically. If multiple profiles match, Loom prompts in the TUI. API clients receive a structured <code>auth_unresolved</code> payload and retry with explicit profile overrides.
  </div>

  <div class="callout callout-warn">
    <strong>Single model?</strong>
    If you only have one model, assign it all four roles: <code>["planner", "executor", "extractor", "verifier"]</code>
  </div>

  <h3>Model Roles Explained</h3>
  <table>
    <tr>
      <th>Role</th>
      <th>What it does</th>
      <th>Ideal model</th>
    </tr>
    <tr>
      <td><code>planner</code></td>
      <td>Decomposes goal into subtasks with dependencies</td>
      <td>Larger, slower, better reasoning (14B+)</td>
    </tr>
    <tr>
      <td><code>executor</code></td>
      <td>Runs tool-calling loops to complete subtasks</td>
      <td>Good at code generation and tool use</td>
    </tr>
    <tr>
      <td><code>extractor</code></td>
      <td>Extracts decisions and discoveries into memory</td>
      <td>Fast, follows JSON format well (8B)</td>
    </tr>
    <tr>
      <td><code>verifier</code></td>
      <td>Independently checks subtask results</td>
      <td>Precise, low temperature (8B)</td>
    </tr>
  </table>
</section>

<!-- ======================== START SERVER ======================== -->
<section id="start-server">
  <h2>4. Starting the Server</h2>

  <div class="progress-track">
    <div class="progress-step done"></div>
    <div class="progress-step done"></div>
    <div class="progress-step done"></div>
    <div class="progress-step done"></div>
    <div class="progress-step"></div>
  </div>

  <pre><code><span class="cmd">loom serve</span>
<span class="cmt"># Starting Loom server on 127.0.0.1:9000</span></code></pre>

  <p>The server binds to <code>127.0.0.1</code> (local only). Override with flags:</p>

  <pre><code><span class="cmd">loom serve</span> <span class="flag">--host</span> 0.0.0.0 <span class="flag">--port</span> 8080</code></pre>

  <h3>Verify it's running</h3>
  <pre><code><span class="cmt"># In another terminal:</span>
<span class="cmd">curl</span> http://localhost:9000/health
<span class="cmt"># {"status":"ok","version":"0.1.0"}</span>

<span class="cmt"># Check configured models:</span>
<span class="cmd">curl</span> http://localhost:9000/models
<span class="cmt"># [{"name":"primary","model":"qwen3:14b","tier":1,"roles":["planner","executor"]}, ...]</span>

<span class="cmt"># Check available tools:</span>
<span class="cmd">curl</span> http://localhost:9000/tools
<span class="cmt"># [{"name":"read_file","description":"..."}, {"name":"write_file","description":"..."}, ...]</span></code></pre>

  <div class="callout callout-success">
    <strong>Interactive API docs</strong>
    Open <code>http://localhost:9000/docs</code> in your browser for the auto-generated Swagger UI.
  </div>
</section>

<!-- ======================== FIRST TASK ======================== -->
<section id="first-task">
  <h2>5. Your First Task</h2>

  <div class="progress-track">
    <div class="progress-step done"></div>
    <div class="progress-step done"></div>
    <div class="progress-step done"></div>
    <div class="progress-step done"></div>
    <div class="progress-step done"></div>
  </div>

  <h3>Step 1: Create a workspace</h3>
  <pre><code><span class="cmd">mkdir</span> <span class="flag">-p</span> /tmp/loom-demo</code></pre>

  <h3>Step 2: Submit a task</h3>
  <pre><code><span class="cmd">curl</span> <span class="flag">-X POST</span> http://localhost:9000/tasks \
  <span class="flag">-H</span> <span class="str">"Content-Type: application/json"</span> \
  <span class="flag">-d</span> <span class="str">'{
    "goal": "Create a Python script that generates random passwords with configurable length and complexity",
    "workspace": "/tmp/loom-demo"
  }'</span></code></pre>

  <p>Response:</p>
  <pre><code>{
  <span class="key">"task_id"</span>: <span class="str">"a1b2c3d4-..."</span>,
  <span class="key">"status"</span>: <span class="str">"pending"</span>,
  <span class="key">"message"</span>: <span class="str">"Task created and execution started."</span>
}</code></pre>

  <h3>Step 3: Check progress</h3>
  <pre><code><span class="cmd">curl</span> http://localhost:9000/tasks/<span class="str">TASK_ID</span></code></pre>

  <p>The response includes the full task state, plan, and progress:</p>
  <pre><code>{
  <span class="key">"task_id"</span>: <span class="str">"a1b2c3d4-..."</span>,
  <span class="key">"goal"</span>: <span class="str">"Create a Python script..."</span>,
  <span class="key">"status"</span>: <span class="str">"executing"</span>,
  <span class="key">"plan"</span>: {
    <span class="key">"version"</span>: <span class="val">1</span>,
    <span class="key">"subtasks"</span>: [
      {<span class="key">"id"</span>: <span class="str">"create-script"</span>, <span class="key">"status"</span>: <span class="str">"completed"</span>},
      {<span class="key">"id"</span>: <span class="str">"add-cli-args"</span>,  <span class="key">"status"</span>: <span class="str">"running"</span>},
      {<span class="key">"id"</span>: <span class="str">"write-tests"</span>,   <span class="key">"status"</span>: <span class="str">"pending"</span>}
    ]
  },
  <span class="key">"progress"</span>: {
    <span class="key">"total_subtasks"</span>: <span class="val">3</span>,
    <span class="key">"completed"</span>: <span class="val">1</span>,
    <span class="key">"percent_complete"</span>: <span class="val">33.3</span>
  }
}</code></pre>

  <h3>Or use the CLI</h3>
  <pre><code><span class="cmd">loom run</span> <span class="str">"Create a password generator script"</span> <span class="flag">--workspace</span> /tmp/loom-demo</code></pre>
  <p>This submits the task and streams progress inline.</p>
</section>

<!-- ======================== STREAMING ======================== -->
<section id="streaming">
  <h2>Streaming Events</h2>

  <p>Watch task execution in real-time via Server-Sent Events (SSE):</p>

  <pre><code><span class="cmd">curl</span> <span class="flag">-N</span> http://localhost:9000/tasks/<span class="str">TASK_ID</span>/stream</code></pre>

  <p>Events arrive as they happen:</p>

  <pre><code><span class="cmt">event:</span> subtask_started
<span class="cmt">data:</span> {"task_id":"a1b2c3d4","subtask_id":"create-script","timestamp":"..."}

<span class="cmt">event:</span> subtask_completed
<span class="cmt">data:</span> {"task_id":"a1b2c3d4","subtask_id":"create-script","status":"success"}

<span class="cmt">event:</span> subtask_started
<span class="cmt">data:</span> {"task_id":"a1b2c3d4","subtask_id":"add-cli-args","timestamp":"..."}

<span class="cmt">event:</span> task_completed
<span class="cmt">data:</span> {"task_id":"a1b2c3d4","status":"completed"}</code></pre>

  <h3>Event Types</h3>
  <table>
    <tr><th>Event</th><th>When</th></tr>
    <tr><td><code>task_planning</code></td><td>Planner model is creating the plan</td></tr>
    <tr><td><code>task_plan_ready</code></td><td>Plan created, execution starting</td></tr>
    <tr><td><code>subtask_started</code></td><td>A subtask begins execution</td></tr>
    <tr><td><code>subtask_completed</code></td><td>A subtask finished successfully</td></tr>
    <tr><td><code>subtask_failed</code></td><td>A subtask failed (may retry or trigger re-planning)</td></tr>
    <tr><td><code>subtask_retrying</code></td><td>A subtask is being retried (with tier escalation info)</td></tr>
    <tr><td><code>task_replanning</code></td><td>Re-planning triggered after subtask failures</td></tr>
    <tr><td><code>tool_call_started</code></td><td>A tool is being invoked</td></tr>
    <tr><td><code>tool_call_completed</code></td><td>A tool call returned</td></tr>
    <tr><td><code>verification_started</code></td><td>Verification check beginning</td></tr>
    <tr><td><code>verification_passed</code></td><td>Verification check passed</td></tr>
    <tr><td><code>verification_failed</code></td><td>Verification check failed</td></tr>
    <tr><td><code>approval_requested</code></td><td>Waiting for human approval (with confidence score)</td></tr>
    <tr><td><code>task_completed</code></td><td>All subtasks done</td></tr>
    <tr><td><code>task_failed</code></td><td>Task could not complete</td></tr>
    <tr><td><code>token_streamed</code></td><td>A model token was generated (streaming mode)</td></tr>
  </table>

  <p>The stream terminates automatically when the task reaches a terminal state (<code>completed</code>, <code>failed</code>, or <code>cancelled</code>). If no events arrive for 30 seconds, a keepalive comment is sent to maintain the connection.</p>
</section>

<!-- ======================== STEERING ======================== -->
<section id="steering">
  <h2>Steering and Feedback</h2>

  <p>Loom supports human-in-the-loop interaction while tasks are running.</p>

  <h3>Inject instructions (steer)</h3>
  <pre><code><span class="cmd">curl</span> <span class="flag">-X PATCH</span> http://localhost:9000/tasks/<span class="str">TASK_ID</span> \
  <span class="flag">-H</span> <span class="str">"Content-Type: application/json"</span> \
  <span class="flag">-d</span> <span class="str">'{"instruction": "Use argparse instead of sys.argv for CLI arguments"}'</span></code></pre>
  <p>The instruction is stored as a memory entry and injected into subsequent model prompts.</p>

  <h3>Approve a gated step</h3>
  <pre><code><span class="cmd">curl</span> <span class="flag">-X POST</span> http://localhost:9000/tasks/<span class="str">TASK_ID</span>/approve \
  <span class="flag">-H</span> <span class="str">"Content-Type: application/json"</span> \
  <span class="flag">-d</span> <span class="str">'{"subtask_id": "deploy-prod", "approved": true, "reason": "Looks good"}'</span></code></pre>

  <h3>Provide feedback</h3>
  <pre><code><span class="cmd">curl</span> <span class="flag">-X POST</span> http://localhost:9000/tasks/<span class="str">TASK_ID</span>/feedback \
  <span class="flag">-H</span> <span class="str">"Content-Type: application/json"</span> \
  <span class="flag">-d</span> <span class="str">'{"feedback": "The generated tests should use pytest, not unittest"}'</span></code></pre>

  <h3>Cancel a task</h3>
  <pre><code><span class="cmd">curl</span> <span class="flag">-X DELETE</span> http://localhost:9000/tasks/<span class="str">TASK_ID</span></code></pre>
</section>

<!-- ======================== TUI ======================== -->
<section id="tui">
  <h2>Interactive TUI</h2>

  <p>Loom's default interface is a rich terminal UI built with <strong>Textual</strong>. It runs the model directly &mdash; no server needed. Just run <code>loom</code>.</p>

  <pre><code><span class="cmt"># Launch the interactive TUI (default command)</span>
<span class="cmd">loom</span> <span class="flag">-w</span> /path/to/project

<span class="cmt"># With a process definition</span>
<span class="cmd">loom</span> <span class="flag">-w</span> /path/to/project <span class="flag">--process</span> consulting-engagement

<span class="cmt"># Activate/switch process at runtime, then force orchestration</span>
<span class="cmd">/process use</span> investment-analysis
<span class="cmd">/run</span> Analyze Tesla for investment
<span class="cmd">/run</span> problem.md
<span class="cmd">/run</span> @problem.md focus on parser regressions

<span class="cmt"># Resume a previous session</span>
<span class="cmd">loom</span> <span class="flag">--resume</span> a1b2c3d4

<span class="cmt"># "loom cowork" is an alias for the same interface</span>
<span class="cmd">loom cowork</span> <span class="flag">-w</span> /path/to/project</code></pre>

  <h3>Layout</h3>
  <p>The TUI has a sidebar with workspace browser and task progress, a main area with tabbed content (Chat, Files Changed, Events), and a status bar showing workspace, model, and token count. Selecting a file in the workspace tree opens a read-only preview modal with renderer support for Markdown, code/text (including TypeScript and CSS with syntax highlighting), JSON, CSV/TSV, HTML, diff/patch, Word/PowerPoint, PDF text extraction, and image metadata.</p>

  <h3>Keyboard Shortcuts</h3>
  <table>
    <tr><th>Key</th><th>Action</th></tr>
    <tr><td><code>Ctrl+B</code></td><td>Toggle sidebar</td></tr>
    <tr><td><code>Ctrl+L</code></td><td>Clear chat</td></tr>
    <tr><td><code>Ctrl+R</code></td><td>Reload workspace tree</td></tr>
    <tr><td><code>Ctrl+W</code></td><td>Close active process-run tab (with confirmation)</td></tr>
    <tr><td><code>Ctrl+P</code></td><td>Command palette</td></tr>
    <tr><td><code>Ctrl+1/2/3</code></td><td>Switch tabs (Chat / Files / Events)</td></tr>
    <tr><td><code>Tab</code></td><td>Cycle slash-command autocomplete (when input starts with <code>/</code>)</td></tr>
    <tr><td><code>Shift+Tab</code></td><td>Cycle slash-command autocomplete backward</td></tr>
    <tr><td><code>Ctrl+C</code></td><td>Quit</td></tr>
  </table>

  <h3>Slash Commands</h3>
  <table>
    <tr><th>Command</th><th>Action</th></tr>
    <tr><td><code>/help</code></td><td>Show available commands and shortcuts</td></tr>
    <tr><td><code>/sessions</code></td><td>List all saved sessions</td></tr>
    <tr><td><code>/new</code></td><td>Start a new session</td></tr>
    <tr><td><code>/session</code></td><td>Show current session info (turns, tokens, focus)</td></tr>
    <tr><td><code>/resume &lt;id&gt;</code></td><td>Switch to a different session</td></tr>
    <tr><td><code>/learned</code></td><td>Review, inspect, and delete learned behavioral patterns</td></tr>
    <tr><td><code>/model</code></td><td>Show current model</td></tr>
    <tr><td><code>/tools</code></td><td>List available tools</td></tr>
    <tr><td><code>/tokens</code></td><td>Show session token usage</td></tr>
    <tr><td><code>/mcp list</code></td><td>List merged MCP server config entries</td></tr>
    <tr><td><code>/mcp show &lt;alias&gt;</code></td><td>Show one MCP config entry (redacted env values)</td></tr>
    <tr><td><code>/mcp test &lt;alias&gt;</code></td><td>Run a <code>tools/list</code> probe against one MCP server</td></tr>
    <tr><td><code>/mcp enable|disable|remove &lt;alias&gt;</code></td><td>Mutate MCP config and refresh runtime MCP tools</td></tr>
    <tr><td><code>/auth</code> / <code>/auth manage</code></td><td>Open the auth profile manager</td></tr>
    <tr><td><code>/auth use selector=profile_id</code></td><td>Set run-local auth override for the next <code>/run</code> (selector can be provider, <code>resource_ref</code>, or <code>resource_id</code>)</td></tr>
    <tr><td><code>/auth select &lt;selector&gt;=&lt;profile_id&gt;</code></td><td>Persist workspace default mapping (selector can be provider, <code>resource_ref</code>, or <code>resource_id</code>)</td></tr>
    <tr><td><code>loom auth sync [--scope active|full]</code></td><td>Auto-discover auth resources and create missing draft profiles</td></tr>
    <tr><td><code>loom auth audit</code></td><td>Report orphaned/dangling auth state (non-zero exit when findings exist)</td></tr>
    <tr><td><code>loom auth migrate [--rollback &lt;snapshot&gt;]</code></td><td>Migrate legacy provider defaults to resource bindings/defaults (auto-rollback on failure), or restore from snapshot</td></tr>
    <tr><td><code>/process list</code></td><td>List discovered process definitions</td></tr>
    <tr><td><code>/process use &lt;name-or-path&gt;</code></td><td>Activate a process in the current session</td></tr>
    <tr><td><code>/process off</code></td><td>Disable the active process</td></tr>
    <tr><td><code>/run &lt;goal&gt;</code></td><td>Force orchestration through the active process (single-token workspace files are treated as goal files)</td></tr>
    <tr><td><code>/run @&lt;goal-file&gt; [goal]</code></td><td>Explicitly load a workspace goal file, optionally with an inline goal override</td></tr>
    <tr><td><code>/run close [run-id-prefix]</code></td><td>Close/cancel a process-run tab with confirmation</td></tr>
    <tr><td><code>/&lt;process-name&gt; &lt;goal&gt;</code></td><td>Run a discovered process directly without changing the active process</td></tr>
    <tr><td><code>/setup</code></td><td>Reconfigure models and settings</td></tr>
    <tr><td><code>/clear</code></td><td>Clear the chat display</td></tr>
    <tr><td><code>/quit</code> (<code>/exit</code>, <code>/q</code>)</td><td>Exit Loom</td></tr>
  </table>

  <h3>Session Persistence</h3>
  <p>Every conversation turn is persisted to SQLite. Sessions survive restarts. The model has access to a <code>conversation_recall</code> tool to search past context that has fallen out of the context window, and a <code>delegate_task</code> tool to spawn autonomous sub-agents for complex work.</p>

  <div class="callout callout-info">
    <strong>About /run</strong>
    <code>/run &lt;goal&gt;</code> uses in-process orchestration via <code>delegate_task</code>. You do not need to run <code>loom serve</code> for this flow. Use <code>/run problem.md</code> to load a workspace goal file directly, or <code>/run @problem.md optional-goal</code> to provide explicit file input with an inline goal. Use <code>/run close</code> (or <code>Ctrl+W</code> on a process tab) to cancel and close a running tab. If the run needs credentials, Loom resolves auth before execution and prompts for profile selection only when required.
  </div>
  <div class="callout callout-info">
    <strong>Auth UX</strong>
    Opening <code>/auth</code> auto-syncs discovered MCP/API/tool auth requirements and creates draft profiles for missing coverage. Provider is derived from the selected target resource in the manager.
  </div>

  <div class="callout callout-info">
    <strong>Tool approval</strong>
    Read-only tools (read_file, search, glob, web_search, etc.) are auto-approved. Write and execute tools show an approval modal: <strong>[y]es</strong>, <strong>[a]lways</strong>, or <strong>[n]o</strong>.
  </div>
</section>

<!-- ======================== PROCESSES ======================== -->
<section id="processes">
  <h2>Process Definitions</h2>

  <p>Process definitions let you specialize Loom for specific domains <strong>without writing any code</strong>. A process definition is a YAML file that injects domain expertise into every stage of the engine: planning, execution, verification, and memory extraction.</p>

  <div class="callout callout-info">
    <strong>Think of it like a programming language</strong>
    The engine is the runtime, built-in tools are the standard library, and process definitions are user programs that configure behavior. Process <em>packages</em> can even bundle custom tools alongside the YAML &mdash; delivering both intelligence and capability in a single unit.
  </div>

  <h3>Built-in Processes</h3>
  <p>Loom ships with 6 domain-specific process definitions:</p>

  <table>
    <tr><th>Process</th><th>Phases</th><th>Mode</th><th>Domain</th></tr>
    <tr><td><code>investment-analysis</code></td><td>8</td><td>strict</td><td>Financial due diligence, valuation, and investment memo synthesis</td></tr>
    <tr><td><code>marketing-strategy</code></td><td>8</td><td>strict</td><td>Go-to-market strategy, channel planning, and execution roadmap</td></tr>
    <tr><td><code>research-report</code></td><td>6</td><td>strict</td><td>Evidence-first research synthesis and quality-controlled reporting</td></tr>
    <tr><td><code>competitive-intel</code></td><td>6</td><td>strict</td><td>Competitive landscape analysis and response playbooks</td></tr>
    <tr><td><code>consulting-engagement</code></td><td>7</td><td>strict</td><td>Structured consulting workflow with issue-tree problem solving</td></tr>
    <tr><td><code>market-research</code></td><td>8</td><td>strict</td><td>Geography-aware market scans, trend analysis, and risk-aware competitor intelligence</td></tr>
  </table>
  <p>All built-in processes currently use <code>strict</code> mode to enforce the declared phase DAG and deliverables.</p>

  <h3>Using a Process</h3>

  <pre><code><span class="cmt"># List all available processes</span>
<span class="cmd">loom processes</span>

<span class="cmt"># Run a task with a specific process</span>
<span class="cmd">loom run</span> <span class="str">"Analyze Tesla for investment"</span> <span class="flag">--workspace</span> /tmp/tesla <span class="flag">--process</span> investment-analysis

<span class="cmt"># Interactive session with a process</span>
<span class="cmd">loom</span> <span class="flag">-w</span> /tmp/project <span class="flag">--process</span> consulting-engagement

<span class="cmt"># Inside the TUI: force the active process</span>
<span class="cmd">/run</span> Analyze Tesla for investment
<span class="cmd">/run</span> problem.md
<span class="cmd">/run</span> @problem.md focus on parser regressions</code></pre>

  <p>In interactive mode, plain chat stays conversational. Use <code>/run &lt;goal&gt;</code> when you want explicit process orchestration for the active process, and use a goal file form when the task spec is too large to type inline.</p>

  <h3>Testing a Process Package</h3>
  <pre><code><span class="cmt"># Run all declared deterministic test cases</span>
<span class="cmd">loom process test</span> investment-analysis

<span class="cmt"># Run one specific case</span>
<span class="cmd">loom process test</span> ./my-local-process <span class="flag">--case</span> smoke

<span class="cmt"># Run only live cases (real providers + external tools)</span>
<span class="cmd">loom process test</span> ./my-local-process <span class="flag">--live</span></code></pre>

  <p>Declare test cases in your <code>process.yaml</code> using a <code>tests:</code> manifest with a unique case ID, mode (<code>deterministic</code> or <code>live</code>), and acceptance checks.</p>

  <pre><code><span class="key">tests</span>:
  - <span class="key">id</span>: <span class="str">smoke</span>
    <span class="key">mode</span>: <span class="str">deterministic</span>
    <span class="key">goal</span>: <span class="str">"Analyze Tesla for investment"</span>
    <span class="key">acceptance</span>:
      <span class="key">deliverables</span>:
        <span class="key">must_exist</span>:
          - <span class="str">company-overview.md</span></code></pre>

  <div class="callout callout-warn">
    <strong>Deliverable names are exact</strong>
    If a process phase declares <code>financial-summary.csv</code>, verification expects that exact filename. Variant names (for example prefixed/suffixed alternatives) will fail deterministic checks.
  </div>

  <h3>What a Process Injects</h3>
  <div class="card-grid">
    <div class="card">
      <h4>Persona</h4>
      <p>Domain-expert identity injected into all prompts (planner, executor, verifier, extractor)</p>
    </div>
    <div class="card">
      <h4>Phase Blueprint</h4>
      <p>Recommended phase structure with dependencies, deliverables, and acceptance criteria</p>
    </div>
    <div class="card">
      <h4>Verification Rules</h4>
      <p>Domain-specific checks &mdash; regex patterns for deterministic validation, LLM rules for semantic review</p>
    </div>
    <div class="card">
      <h4>Tool Guidance</h4>
      <p>Instructions on which tools to use and how, plus tool exclusions for irrelevant tools</p>
    </div>
  </div>

  <h3>Phase Modes</h3>
  <table>
    <tr><th>Mode</th><th>Planner Freedom</th><th>Use When</th></tr>
    <tr><td><code>strict</code></td><td>Must follow the phase blueprint exactly</td><td>Regulatory, financial, compliance workflows</td></tr>
    <tr><td><code>guided</code></td><td>Should follow the blueprint but can adapt</td><td>Most domain work (recommended default)</td></tr>
    <tr><td><code>suggestive</code></td><td>Blueprint is optional inspiration</td><td>Creative or exploratory tasks</td></tr>
  </table>

  <h3>Creating Custom Processes</h3>
  <p>Drop a YAML file in <code>~/.loom/processes/</code> or <code>&lt;workspace&gt;/.loom/processes/</code>:</p>

  <pre><code><span class="label">my-process.yaml</span>
<span class="key">name</span>: <span class="str">my-custom-process</span>
<span class="key">version</span>: <span class="str">"1.0"</span>
<span class="key">description</span>: <span class="str">"My domain specialization"</span>
<span class="key">persona</span>: <span class="str">|
  You are a domain expert specializing in...</span>

<span class="key">phase_mode</span>: <span class="str">guided</span>

<span class="key">phases</span>:
  - <span class="key">id</span>: <span class="str">research</span>
    <span class="key">description</span>: <span class="str">"Gather and analyze data"</span>
    <span class="key">depends_on</span>: []
    <span class="key">deliverables</span>:
      - <span class="str">"research-notes.md"</span>

  - <span class="key">id</span>: <span class="str">synthesize</span>
    <span class="key">description</span>: <span class="str">"Create final report"</span>
    <span class="key">depends_on</span>: [<span class="str">research</span>]
    <span class="key">deliverables</span>:
      - <span class="str">"final-report.md"</span>

<span class="key">verification</span>:
  <span class="key">rules</span>:
    - <span class="key">name</span>: <span class="str">no-placeholders</span>
      <span class="key">check</span>: <span class="str">"(?i)(TODO|PLACEHOLDER|TBD)"</span>
      <span class="key">severity</span>: <span class="str">error</span>
      <span class="key">type</span>: <span class="str">regex</span></code></pre>

  <h3>Process Discovery Order</h3>
  <p>Loom searches for process definitions in this order (first match wins):</p>
  <ol style="padding-left: 24px; margin: 12px 0; color: var(--text-dim);">
    <li><code>&lt;workspace&gt;/.loom/processes/</code> &mdash; workspace-local</li>
    <li>Paths from <code>[process] search_paths</code> in config &mdash; user-global</li>
    <li>Built-in processes shipped with Loom</li>
  </ol>

  <h3>Installing Process Packages</h3>
  <p>Process packages can be installed from GitHub repos with <code>loom install</code>. The installer validates structure, auto-installs Python dependencies, and places the package into your discovery path.</p>

  <pre><code><span class="cmt"># From GitHub URL or shorthand</span>
<span class="cmd">loom install</span> https://github.com/acme/loom-google-analytics
<span class="cmd">loom install</span> acme/loom-google-analytics

<span class="cmt"># From local directory</span>
<span class="cmd">loom install</span> ./my-local-process

<span class="cmt"># Into a specific workspace</span>
<span class="cmd">loom install</span> ./my-process -w /path/to/project

<span class="cmt"># Remove an installed process</span>
<span class="cmd">loom uninstall</span> google-analytics</code></pre>

  <p>Declare Python dependencies in <code>process.yaml</code> â€” they're auto-installed during <code>loom install</code>:</p>

  <pre><code><span class="key">name</span>: <span class="str">google-analytics</span>
<span class="key">dependencies</span>:
  - <span class="str">google-analytics-data>=0.18.0</span>
  - <span class="str">pandas>=2.0</span></code></pre>

  <div class="callout callout-success">
    <strong>New tools included</strong>
    Three new tools complement the process system: <code>calculator</code> (safe math with financial functions like NPV, CAGR, WACC), <code>spreadsheet</code> (CSV operations), and <code>document_write</code> (structured Markdown generation).
  </div>
</section>

<!-- ======================== APPROVAL ======================== -->
<section id="approval">
  <h2>Approval Gates</h2>

  <p>Loom has a <strong>confidence scoring</strong> and <strong>approval gate</strong> system that controls when subtasks proceed automatically vs. waiting for human approval.</p>

  <h3>Confidence Scoring</h3>
  <p>After each subtask executes and is verified, Loom computes a confidence score (0.0 to 1.0) based on weighted factors:</p>

  <table>
    <tr><th>Factor</th><th>Weight</th><th>What it measures</th></tr>
    <tr><td>Verification tier 1 passed</td><td>0.3</td><td>Deterministic checks (syntax, files exist)</td></tr>
    <tr><td>Verification tier 2 passed</td><td>0.3</td><td>Independent LLM review agreed</td></tr>
    <tr><td>No prior retries</td><td>0.2</td><td>Succeeded on first attempt</td></tr>
    <tr><td>Non-destructive operation</td><td>0.1</td><td>No rm, sudo, DROP, etc.</td></tr>
    <tr><td>All tool calls succeeded</td><td>0.1</td><td>No tool errors during execution</td></tr>
  </table>

  <p>Scores are classified into bands: <strong>high</strong> (&ge;0.8), <strong>medium</strong> (&ge;0.5), <strong>low</strong> (&ge;0.2), <strong>zero</strong> (&lt;0.2).</p>

  <h3>Approval Modes</h3>
  <div class="card-grid">
    <div class="card">
      <h4>Auto</h4>
      <p>Proceeds if confidence is high (&ge;0.8). Pauses for human approval otherwise. Default mode.</p>
    </div>
    <div class="card">
      <h4>Manual</h4>
      <p>Always waits for human approval before proceeding to the next subtask.</p>
    </div>
    <div class="card">
      <h4>Confidence Threshold</h4>
      <p>You set a custom threshold. Proceeds automatically if confidence meets it.</p>
    </div>
    <div class="card">
      <h4>Always-Gate</h4>
      <p>Destructive operations (rm -rf, sudo, DROP TABLE, .env access) always require approval regardless of mode.</p>
    </div>
  </div>

  <h3>Retry Escalation</h3>
  <p>When a subtask fails, Loom automatically retries with an escalation ladder:</p>

  <div class="step">
    <div class="step-number">1</div>
    <div class="step-content">
      <h4>Attempts 0-1: Same tier</h4>
      <p>Retry with the same model at the same tier level</p>
    </div>
  </div>
  <div class="step">
    <div class="step-number">2</div>
    <div class="step-content">
      <h4>Attempt 2: Escalate</h4>
      <p>Promote to the next model tier (e.g., from 8B to 14B)</p>
    </div>
  </div>
  <div class="step">
    <div class="step-number">3</div>
    <div class="step-content">
      <h4>Attempt 3+: Max tier</h4>
      <p>Use the highest available model tier</p>
    </div>
  </div>
  <div class="step">
    <div class="step-number">4</div>
    <div class="step-content">
      <h4>Max retries exceeded: Flag for human</h4>
      <p>Stop and request human intervention</p>
    </div>
  </div>

  <h3>Webhooks</h3>
  <p>Get notified when tasks complete by providing a <code>callback_url</code> when creating a task:</p>
  <pre><code><span class="cmd">curl</span> <span class="flag">-X POST</span> http://localhost:9000/tasks \
  <span class="flag">-H</span> <span class="str">"Content-Type: application/json"</span> \
  <span class="flag">-d</span> <span class="str">'{
    "goal": "Run the test suite",
    "workspace": "/tmp/project",
    "callback_url": "https://your-server.com/webhook"
  }'</span></code></pre>
  <p>Loom will POST to the callback URL when the task reaches a terminal state (completed, failed, or cancelled), with automatic retry and exponential backoff on delivery failures.</p>
</section>

<!-- ======================== LEARNING ======================== -->
<section id="learning">
  <h2>Adaptive Learning</h2>

  <p>Loom learns from your interactions so you never repeat yourself. Two learning modes work together:</p>

  <div class="card-grid">
    <div class="card">
      <h4>Operational Learning</h4>
      <p>After every autonomous task, Loom extracts model success rates, retry patterns, and successful plan templates. These inform future model selection and planning.</p>
    </div>
    <div class="card">
      <h4>Behavioral Learning</h4>
      <p>Loom detects the gap between what the model delivered and what you actually wanted. Implicit follow-ups ("test and lint it") and explicit corrections ("no, use JSON") are captured as general behavioral rules and injected into future prompts.</p>
    </div>
  </div>

  <h3>Pattern Types</h3>
  <table>
    <tr><th>Type</th><th>Source</th><th>Example</th></tr>
    <tr><td><code>behavioral_gap</code></td><td>Implicit &mdash; user had to ask for something the model should have done</td><td>"Run tests after writing code"</td></tr>
    <tr><td><code>behavioral_correction</code></td><td>Explicit &mdash; user contradicted the model's output</td><td>"Use JSON not YAML"</td></tr>
    <tr><td><code>subtask_success</code></td><td>Post-task &mdash; model success rates per subtask type</td><td>Success rate for "install-deps"</td></tr>
    <tr><td><code>retry_pattern</code></td><td>Post-task &mdash; which subtasks needed escalation</td><td>"Schema conversion needs tier 2"</td></tr>
    <tr><td><code>task_template</code></td><td>Post-task &mdash; successful plans as reusable templates</td><td>7-step migration plan</td></tr>
  </table>

  <p>Patterns are frequency-weighted &mdash; the more a pattern is observed, the higher it ranks. High-frequency patterns persist indefinitely; low-frequency ones are pruned after 90 days. All data stays local in your SQLite database.</p>

  <h3>Reviewing and Managing Patterns</h3>
  <pre><code><span class="cmt"># List learned behavioral patterns (default)</span>
<span class="cmd">loom learned</span>

<span class="cmt"># Include internal operational patterns</span>
<span class="cmd">loom learned</span> <span class="flag">--all</span>

<span class="cmt"># Filter by type</span>
<span class="cmd">loom learned</span> <span class="flag">--type</span> behavioral_gap

<span class="cmt"># Delete a specific pattern by ID</span>
<span class="cmd">loom learned</span> <span class="flag">--delete</span> <span class="val">5</span>

<span class="cmt"># Clear all learned patterns (start fresh)</span>
<span class="cmd">loom reset-learning</span></code></pre>

  <p>In the TUI, use <code>/learned</code> to open an interactive review screen for behavioral patterns, where you can inspect each pattern's type, description, frequency count, and last-seen date, and delete individual patterns with a single click.</p>

  <div class="callout callout-info">
    <strong>How gap detection works</strong>
    When the model delivers a response it considers complete ("Here's the code, hope that helps"), Loom marks that as a completion point. If you follow up with a continuation or correction instead of a new topic, Loom extracts a general behavioral rule from the gap and stores it for future prompt injection.
  </div>
</section>

<!-- ======================== MCP ======================== -->
<section id="mcp">
  <h2>MCP Server</h2>

  <p>Loom can act as a <strong>Model Context Protocol (MCP)</strong> tool server, letting other AI agents delegate tasks to Loom.</p>

  <pre><code><span class="cmt"># Start the MCP server (stdio transport)</span>
<span class="cmd">loom mcp-serve</span>

<span class="cmt"># Connect to a different Loom API</span>
<span class="cmd">loom mcp-serve</span> <span class="flag">--server</span> http://localhost:8080</code></pre>

  <pre><code><span class="cmt"># Manage external MCP server configs</span>
<span class="cmd">loom mcp list</span>
<span class="cmd">loom mcp add notion</span> <span class="flag">--command</span> npx <span class="flag">--arg</span> -y <span class="flag">--arg</span> @modelcontextprotocol/server-notion <span class="flag">--env-ref</span> NOTION_TOKEN=NOTION_TOKEN
<span class="cmd">loom mcp test notion</span>
<span class="cmd">loom mcp migrate</span></code></pre>

  <div class="callout callout-info">
    <strong>Requires extra</strong>
    Install with <code>uv sync --extra mcp</code> or <code>pip install -e ".[mcp]"</code>.
  </div>

  <h3>Exposed Tools</h3>
  <table>
    <tr><th>Tool</th><th>Description</th></tr>
    <tr><td><code>loom_execute_task</code></td><td>Create and run a task. Supports <code>wait: true</code> to block until completion.</td></tr>
    <tr><td><code>loom_task_status</code></td><td>Check current status of a task by ID</td></tr>
    <tr><td><code>loom_list_tasks</code></td><td>List all tasks, optionally filtered by status</td></tr>
  </table>

  <p>Any MCP-compatible client (Claude Desktop, other agents) can connect to Loom over stdio and use these tools to orchestrate complex coding tasks.</p>
</section>

<!-- ======================== ENDPOINTS ======================== -->
<section id="endpoints">
  <h2>API Endpoints</h2>

  <h3>Task Lifecycle</h3>
  <div class="endpoint"><span class="method method-post">POST</span><span class="endpoint-path">/tasks</span><span class="endpoint-desc">Create and start a task</span></div>
  <div class="endpoint"><span class="method method-get">GET</span><span class="endpoint-path">/tasks</span><span class="endpoint-desc">List all tasks (filter with ?status=)</span></div>
  <div class="endpoint"><span class="method method-get">GET</span><span class="endpoint-path">/tasks/{id}</span><span class="endpoint-desc">Full task state, plan, and progress</span></div>
  <div class="endpoint"><span class="method method-get">GET</span><span class="endpoint-path">/tasks/{id}/stream</span><span class="endpoint-desc">SSE event stream</span></div>
  <div class="endpoint"><span class="method method-get">GET</span><span class="endpoint-path">/tasks/{id}/tokens</span><span class="endpoint-desc">SSE token stream</span></div>
  <div class="endpoint"><span class="method method-patch">PATCH</span><span class="endpoint-path">/tasks/{id}</span><span class="endpoint-desc">Inject instructions (steer)</span></div>
  <div class="endpoint"><span class="method method-delete">DELETE</span><span class="endpoint-path">/tasks/{id}</span><span class="endpoint-desc">Cancel a running task</span></div>
  <div class="endpoint"><span class="method method-post">POST</span><span class="endpoint-path">/tasks/{id}/approve</span><span class="endpoint-desc">Approve/reject a gated step</span></div>
  <div class="endpoint"><span class="method method-post">POST</span><span class="endpoint-path">/tasks/{id}/feedback</span><span class="endpoint-desc">Provide mid-task feedback</span></div>
  <div class="endpoint"><span class="method method-post">POST</span><span class="endpoint-path">/tasks/{id}/message</span><span class="endpoint-desc">Inject conversational message</span></div>
  <div class="endpoint"><span class="method method-get">GET</span><span class="endpoint-path">/tasks/{id}/conversation</span><span class="endpoint-desc">Read injected conversation messages</span></div>

  <h3>Subtasks</h3>
  <div class="endpoint"><span class="method method-get">GET</span><span class="endpoint-path">/tasks/{id}/subtasks</span><span class="endpoint-desc">List all subtasks with status</span></div>
  <div class="endpoint"><span class="method method-get">GET</span><span class="endpoint-path">/tasks/{id}/subtasks/{sub_id}</span><span class="endpoint-desc">Subtask detail</span></div>

  <h3>Memory</h3>
  <div class="endpoint"><span class="method method-get">GET</span><span class="endpoint-path">/tasks/{id}/memory</span><span class="endpoint-desc">Query task memory (?entry_type=)</span></div>
  <div class="endpoint"><span class="method method-get">GET</span><span class="endpoint-path">/memory/search</span><span class="endpoint-desc">Search memory (?q=&amp;task_id=)</span></div>

  <h3>System</h3>
  <div class="endpoint"><span class="method method-get">GET</span><span class="endpoint-path">/models</span><span class="endpoint-desc">Available models and roles</span></div>
  <div class="endpoint"><span class="method method-get">GET</span><span class="endpoint-path">/tools</span><span class="endpoint-desc">Available tools and schemas</span></div>
  <div class="endpoint"><span class="method method-get">GET</span><span class="endpoint-path">/health</span><span class="endpoint-desc">Health check</span></div>
  <div class="endpoint"><span class="method method-get">GET</span><span class="endpoint-path">/config</span><span class="endpoint-desc">Current configuration</span></div>

  <div class="callout callout-info">
    <strong>OpenAPI / Swagger</strong>
    Interactive API docs with "Try it out" are available at <code>http://localhost:9000/docs</code> while the server is running.
  </div>
</section>

<!-- ======================== SSE ======================== -->
<section id="sse">
  <h2>SSE Streaming Details</h2>

  <p>The <code>/tasks/{id}/stream</code> endpoint uses <strong>Server-Sent Events</strong> (SSE), a standard HTTP streaming protocol supported by all browsers and most HTTP clients.</p>

  <h3>JavaScript client</h3>
  <pre><code><span class="cmt">// Browser or Node.js with EventSource</span>
<span class="key">const</span> source = <span class="key">new</span> EventSource(<span class="str">`http://localhost:9000/tasks/${taskId}/stream`</span>);

source.addEventListener(<span class="str">'subtask_started'</span>, (e) => {
  <span class="key">const</span> data = JSON.parse(e.data);
  console.log(<span class="str">`Started: ${data.subtask_id}`</span>);
});

source.addEventListener(<span class="str">'task_completed'</span>, (e) => {
  console.log(<span class="str">'Task done!'</span>);
  source.close();
});

source.addEventListener(<span class="str">'task_failed'</span>, (e) => {
  console.error(<span class="str">'Task failed'</span>, JSON.parse(e.data));
  source.close();
});</code></pre>

  <h3>Python client</h3>
  <pre><code><span class="key">import</span> httpx

<span class="key">with</span> httpx.stream(<span class="str">"GET"</span>, <span class="str">f"http://localhost:9000/tasks/{task_id}/stream"</span>) <span class="key">as</span> r:
    <span class="key">for</span> line <span class="key">in</span> r.iter_lines():
        <span class="key">if</span> line.startswith(<span class="str">"data: "</span>):
            print(line[<span class="val">6</span>:])</code></pre>

  <h3>curl</h3>
  <pre><code><span class="cmt"># -N disables output buffering for real-time display</span>
<span class="cmd">curl</span> <span class="flag">-N</span> http://localhost:9000/tasks/<span class="str">TASK_ID</span>/stream</code></pre>
</section>

<!-- ======================== MEMORY ======================== -->
<section id="memory">
  <h2>Memory System</h2>

  <p>Loom maintains a three-layer memory architecture:</p>

  <div class="step">
    <div class="step-number">1</div>
    <div class="step-content">
      <h4>Always-in-Context (YAML State)</h4>
      <p>Current task state, plan, and subtask status. Injected into every prompt.</p>
    </div>
  </div>

  <div class="step">
    <div class="step-number">2</div>
    <div class="step-content">
      <h4>Structured Archive (SQLite)</h4>
      <p>Extracted decisions, errors, discoveries, tool results. Queryable by task, subtask, type, and tags.</p>
    </div>
  </div>

  <div class="step">
    <div class="step-number">3</div>
    <div class="step-content">
      <h4>Vector Search (Future)</h4>
      <p>Semantic similarity search across all memory. Coming in a future release.</p>
    </div>
  </div>

  <h3>Memory Entry Types</h3>
  <table>
    <tr><th>Type</th><th>Description</th></tr>
    <tr><td><code>decision</code></td><td>Architectural or implementation choices made</td></tr>
    <tr><td><code>error</code></td><td>Errors encountered and how they were resolved</td></tr>
    <tr><td><code>tool_result</code></td><td>Important tool call outputs</td></tr>
    <tr><td><code>user_instruction</code></td><td>Instructions injected via steer/feedback</td></tr>
    <tr><td><code>discovery</code></td><td>New information discovered during execution</td></tr>
    <tr><td><code>artifact</code></td><td>Files or outputs created</td></tr>
    <tr><td><code>context</code></td><td>Background information for the task</td></tr>
  </table>

  <h3>Querying Memory</h3>
  <pre><code><span class="cmt"># All memory for a task</span>
<span class="cmd">curl</span> http://localhost:9000/tasks/<span class="str">TASK_ID</span>/memory

<span class="cmt"># Filter by type</span>
<span class="cmd">curl</span> http://localhost:9000/tasks/<span class="str">TASK_ID</span>/memory?entry_type=decision

<span class="cmt"># Search across memory</span>
<span class="cmd">curl</span> <span class="str">"http://localhost:9000/memory/search?q=database&task_id=TASK_ID"</span></code></pre>
</section>

<!-- ======================== ARCHITECTURE ======================== -->
<section id="architecture">
  <h2>Architecture</h2>

  <div class="diagram" style="text-align: left; padding: 24px 32px;">
<span class="dim">       </span><span class="highlight">TUI</span><span class="dim"> --- </span><span class="highlight">CLI</span><span class="dim"> --- </span><span class="highlight">MCP Server</span>
<span class="dim">              \     |     /</span>
<span class="dim">          </span><span class="highlight">API Server</span><span class="dim"> (FastAPI)</span>
<span class="dim">                 |</span>
<span class="dim">             </span><span class="highlight">Engine</span>
<span class="dim">          /    |    \       \</span>
<span class="dim"> </span><span class="highlight">Orchestrator</span><span class="dim"> </span><span class="highlight">EventBus</span><span class="dim"> </span><span class="highlight">StateManager</span><span class="dim"> </span><span class="highlight">Learning</span>
<span class="dim">      |          |</span>
<span class="dim"> </span><span class="highlight">Scheduler</span><span class="dim"> -- </span><span class="highlight">Verification</span><span class="dim"> -- </span><span class="highlight">PromptAssembler</span>
<span class="dim">      |          |               |</span>
<span class="dim"> </span><span class="highlight">ModelRouter</span><span class="dim">  </span><span class="highlight">Confidence</span><span class="dim">    </span><span class="highlight">Templates</span>
<span class="dim">    /     \      |</span>
<span class="dim"> </span><span class="highlight">Ollama</span><span class="dim">  </span><span class="highlight">OpenAI</span><span class="dim"> </span><span class="highlight">Approval</span><span class="dim"> + </span><span class="highlight">Retry</span><span class="dim"> + </span><span class="highlight">Webhook</span>
  </div>

  <h3>Source Layout</h3>
  <pre><code>src/loom/
  __main__.py            <span class="cmt"># CLI (Click), TUI launcher (default command)</span>
  config.py              <span class="cmt"># TOML config loader</span>
  api/
    server.py            <span class="cmt"># FastAPI app + lifespan</span>
    routes.py            <span class="cmt"># All REST endpoints</span>
    schemas.py           <span class="cmt"># Pydantic models</span>
    engine.py            <span class="cmt"># Component wiring</span>
  cowork/
    session.py           <span class="cmt"># CoworkSession â€” core conversation engine</span>
    session_state.py     <span class="cmt"># Session metadata tracking</span>
    approval.py          <span class="cmt"># Per-tool-call approval system</span>
  engine/
    orchestrator.py      <span class="cmt"># Plan -> execute -> verify -> finalize</span>
    scheduler.py         <span class="cmt"># Dependency resolution</span>
    verification.py      <span class="cmt"># Three-tier verification gates</span>
  events/
    bus.py               <span class="cmt"># Pub/sub event bus + persistence</span>
    types.py             <span class="cmt"># Event constants</span>
    webhook.py           <span class="cmt"># Callback URL delivery + retry</span>
  integrations/
    mcp_server.py        <span class="cmt"># MCP server (3 tools)</span>
  learning/
    manager.py           <span class="cmt"># Pattern storage, query, delete, prune</span>
    reflection.py        <span class="cmt"># Gap analysis engine (behavioral learning)</span>
  models/
    base.py              <span class="cmt"># Provider ABC</span>
    ollama_provider.py   <span class="cmt"># Ollama client</span>
    openai_provider.py   <span class="cmt"># OpenAI-compatible client</span>
    router.py            <span class="cmt"># Role + tier routing</span>
  processes/
    schema.py            <span class="cmt"># Process definition loader + validation</span>
    installer.py         <span class="cmt"># Install/uninstall from GitHub or local path</span>
    builtin/             <span class="cmt"># 6 built-in YAML process definitions</span>
  prompts/
    assembler.py         <span class="cmt"># 7-section builder + process injection</span>
    constraints.py       <span class="cmt"># Safety rules</span>
    templates/           <span class="cmt"># YAML templates</span>
  recovery/
    approval.py          <span class="cmt"># Approval gates</span>
    confidence.py        <span class="cmt"># Weighted confidence scoring</span>
    retry.py             <span class="cmt"># Retry escalation ladder</span>
  state/
    task_state.py        <span class="cmt"># Task/Subtask dataclasses</span>
    memory.py            <span class="cmt"># SQLite memory archive</span>
    conversation_store.py<span class="cmt"># Session persistence + recall</span>
    schema.sql           <span class="cmt"># DB schema</span>
  tools/
    registry.py          <span class="cmt"># Tool ABC + auto-discovery</span>
    file_ops.py          <span class="cmt"># Read/write/edit/delete/move</span>
    shell.py             <span class="cmt"># Shell execution</span>
    git.py               <span class="cmt"># Git operations</span>
    search.py            <span class="cmt"># File search</span>
    code_analysis.py     <span class="cmt"># Code structure analysis</span>
    treesitter.py        <span class="cmt"># Tree-sitter backend (optional)</span>
    web.py               <span class="cmt"># Web fetch</span>
    web_search.py        <span class="cmt"># DuckDuckGo search</span>
    ripgrep.py           <span class="cmt"># Ripgrep content search</span>
    glob_find.py         <span class="cmt"># Glob pattern file search</span>
    calculator.py        <span class="cmt"># Safe math + financial functions</span>
    spreadsheet.py       <span class="cmt"># CSV spreadsheet operations</span>
    document_write.py    <span class="cmt"># Structured Markdown generation</span>
    conversation_recall.py <span class="cmt"># Search past conversation context</span>
    delegate_task.py     <span class="cmt"># Spawn sub-agent tasks</span>
    task_tracker.py      <span class="cmt"># Task progress tracking</span>
    ask_user.py          <span class="cmt"># Mid-execution user questions</span>
    workspace.py         <span class="cmt"># Changelog + revert</span>
  tui/
    app.py               <span class="cmt"># Textual TUI â€” unified interactive interface</span>
    widgets/             <span class="cmt"># Chat log, sidebar, status bar, panels</span>
    screens/             <span class="cmt"># Tool approval, ask_user, learned patterns modals</span></code></pre>
</section>

<!-- ======================== CONFIG REF ======================== -->
<section id="config-ref">
  <h2>Configuration Reference</h2>

  <p>This section highlights common runtime config keys. For the full key-by-key reference (including normalization rules), see <a href="CONFIG.md"><code>docs/CONFIG.md</code></a>.</p>

  <h3>Server</h3>
  <table>
    <tr><th>Key</th><th>Default</th><th>Description</th></tr>
    <tr><td><code>server.host</code></td><td><code>127.0.0.1</code></td><td>Server bind address</td></tr>
    <tr><td><code>server.port</code></td><td><code>9000</code></td><td>Server port</td></tr>
  </table>

  <h3>Models</h3>
  <table>
    <tr><th>Key</th><th>Default</th><th>Description</th></tr>
    <tr><td><code>models.*.provider</code></td><td>required</td><td><code>ollama</code>, <code>openai_compatible</code>, or <code>anthropic</code></td></tr>
    <tr><td><code>models.*.base_url</code></td><td>--</td><td>Model API endpoint URL</td></tr>
    <tr><td><code>models.*.model</code></td><td>--</td><td>Model identifier string</td></tr>
    <tr><td><code>models.*.max_tokens</code></td><td><code>8192</code></td><td>Max response tokens</td></tr>
    <tr><td><code>models.*.temperature</code></td><td><code>0.1</code></td><td>Sampling temperature</td></tr>
    <tr><td><code>models.*.roles</code></td><td><code>["executor"]</code></td><td>Assigned roles (planner, executor, extractor, verifier, compactor)</td></tr>
    <tr><td><code>models.*.api_key</code></td><td><code>""</code></td><td>Provider API key</td></tr>
    <tr><td><code>models.*.reasoning_effort</code></td><td><code>""</code></td><td>Optional provider-specific reasoning hint</td></tr>
    <tr><td><code>models.*.tier</code></td><td><code>0</code></td><td>Explicit tier override (<code>0</code> = auto)</td></tr>
    <tr><td><code>models.*.capabilities.*</code></td><td>auto-detected</td><td>Optional capability overrides (<code>vision</code>, <code>native_pdf</code>, <code>thinking</code>, <code>citations</code>, <code>audio_input</code>, <code>audio_output</code>)</td></tr>
  </table>

  <h3>Workspace</h3>
  <table>
    <tr><th>Key</th><th>Default</th><th>Description</th></tr>
    <tr><td><code>workspace.default_path</code></td><td><code>~/projects</code></td><td>Default workspace directory</td></tr>
    <tr><td><code>workspace.scratch_dir</code></td><td><code>~/.loom/scratch</code></td><td>Temporary state storage</td></tr>
  </table>

  <h3>Execution</h3>
  <table>
    <tr><th>Key</th><th>Default</th><th>Description</th></tr>
    <tr><td><code>execution.max_subtask_retries</code></td><td><code>3</code></td><td>Max retries per failed subtask</td></tr>
    <tr><td><code>execution.max_loop_iterations</code></td><td><code>50</code></td><td>Max tool-call loops per subtask</td></tr>
    <tr><td><code>execution.max_parallel_subtasks</code></td><td><code>3</code></td><td>Max concurrent runnable subtasks</td></tr>
    <tr><td><code>execution.auto_approve_confidence_threshold</code></td><td><code>0.8</code></td><td>Auto-approve if confidence above this</td></tr>
    <tr><td><code>execution.enable_streaming</code></td><td><code>false</code></td><td>Enable streaming behavior where supported</td></tr>
    <tr><td><code>execution.delegate_task_timeout_seconds</code></td><td><code>3600</code></td><td>Timeout budget for delegated orchestration (<code>/run</code>, <code>delegate_task</code>)</td></tr>
    <tr><td><code>execution.model_call_max_attempts</code></td><td><code>5</code></td><td>Model-call retry attempt cap</td></tr>
    <tr><td><code>execution.model_call_retry_base_delay_seconds</code></td><td><code>0.5</code></td><td>Base backoff delay for model retries</td></tr>
    <tr><td><code>execution.model_call_retry_max_delay_seconds</code></td><td><code>8.0</code></td><td>Max backoff delay for model retries</td></tr>
    <tr><td><code>execution.model_call_retry_jitter_seconds</code></td><td><code>0.25</code></td><td>Retry jitter added to model-call backoff</td></tr>
  </table>

  <h3>Verification</h3>
  <table>
    <tr><th>Key</th><th>Default</th><th>Description</th></tr>
    <tr><td><code>verification.tier1_enabled</code></td><td><code>true</code></td><td>Deterministic checks (syntax, file existence, tool success)</td></tr>
    <tr><td><code>verification.tier2_enabled</code></td><td><code>true</code></td><td>Independent LLM verification (different model, fresh context)</td></tr>
    <tr><td><code>verification.tier3_enabled</code></td><td><code>false</code></td><td>Multi-vote verification (N checks, majority agreement)</td></tr>
    <tr><td><code>verification.tier3_vote_count</code></td><td><code>3</code></td><td>Number of independent votes for tier 3</td></tr>
    <tr><td><code>verification.policy_engine_enabled</code></td><td><code>true</code></td><td>Enable process policy behavior in verification</td></tr>
    <tr><td><code>verification.regex_default_advisory</code></td><td><code>true</code></td><td>Treat regex rules as advisory unless explicitly hard</td></tr>
    <tr><td><code>verification.strict_output_protocol</code></td><td><code>true</code></td><td>Enforce verifier output protocol handling</td></tr>
    <tr><td><code>verification.shadow_compare_enabled</code></td><td><code>false</code></td><td>Emit shadow comparison telemetry</td></tr>
    <tr><td><code>verification.phase_scope_default</code></td><td><code>current_phase</code></td><td>Default rule scope (<code>current_phase</code> or <code>global</code>)</td></tr>
    <tr><td><code>verification.allow_partial_verified</code></td><td><code>true</code></td><td>Allow partial-verified outcomes when supported</td></tr>
    <tr><td><code>verification.unconfirmed_supporting_threshold</code></td><td><code>0.30</code></td><td>Threshold for unconfirmed supporting evidence handling</td></tr>
    <tr><td><code>verification.auto_confirm_prune_critical_path</code></td><td><code>true</code></td><td>Auto-run remediation attempts for critical-path failures</td></tr>
    <tr><td><code>verification.confirm_or_prune_max_attempts</code></td><td><code>2</code></td><td>Max remediation attempts in confirm/prune flow</td></tr>
    <tr><td><code>verification.confirm_or_prune_backoff_seconds</code></td><td><code>2.0</code></td><td>Backoff between remediation attempts</td></tr>
    <tr><td><code>verification.confirm_or_prune_retry_on_transient</code></td><td><code>true</code></td><td>Retry remediation when transient errors are detected</td></tr>
  </table>

  <h3>Memory and Logging</h3>
  <table>
    <tr><th>Key</th><th>Default</th><th>Description</th></tr>
    <tr><td><code>memory.database_path</code></td><td><code>~/.loom/loom.db</code></td><td>SQLite database location</td></tr>
    <tr><td><code>logging.level</code></td><td><code>INFO</code></td><td>Log verbosity (DEBUG, INFO, WARN, ERROR)</td></tr>
    <tr><td><code>logging.event_log_path</code></td><td><code>~/.loom/logs</code></td><td>Event log directory</td></tr>
  </table>

  <h3>Process</h3>
  <table>
    <tr><th>Key</th><th>Default</th><th>Description</th></tr>
    <tr><td><code>process.default</code></td><td><code>""</code></td><td>Default process definition for all tasks</td></tr>
    <tr><td><code>process.search_paths</code></td><td><code>[]</code></td><td>Additional directories for process discovery</td></tr>
    <tr><td><code>process.require_rule_scope_metadata</code></td><td><code>false</code></td><td>Enforce strict rule scope metadata validation</td></tr>
    <tr><td><code>process.require_v2_contract</code></td><td><code>false</code></td><td>Require process contract <code>schema_version: 2</code></td></tr>
    <tr><td><code>process.tui_run_scoped_workspace_enabled</code></td><td><code>true</code></td><td>Create per-run subfolders for TUI <code>/run</code></td></tr>
    <tr><td><code>process.llm_run_folder_naming_enabled</code></td><td><code>true</code></td><td>Allow model-generated names for run folders (guarded; low-quality names fall back to deterministic slugs)</td></tr>
  </table>

  <h3>MCP (Legacy in <code>loom.toml</code>)</h3>
  <table>
    <tr><th>Key</th><th>Default</th><th>Description</th></tr>
    <tr><td><code>mcp.servers.*.command</code></td><td><code>""</code></td><td>Command used to launch MCP server process</td></tr>
    <tr><td><code>mcp.servers.*.args</code></td><td><code>[]</code></td><td>Command arguments</td></tr>
    <tr><td><code>mcp.servers.*.env</code></td><td><code>{}</code></td><td>Environment variables for MCP server process</td></tr>
    <tr><td><code>mcp.servers.*.cwd</code></td><td><code>""</code></td><td>Working directory for MCP server process</td></tr>
    <tr><td><code>mcp.servers.*.timeout_seconds</code></td><td><code>30</code></td><td>Timeout budget for MCP server calls</td></tr>
    <tr><td><code>mcp.servers.*.enabled</code></td><td><code>true</code></td><td>Enable/disable MCP server</td></tr>
  </table>

  <h3>Environment Override</h3>
  <table>
    <tr><th>Env Var</th><th>Overrides</th><th>Description</th></tr>
    <tr><td><code>LOOM_DELEGATE_TIMEOUT_SECONDS</code></td><td><code>execution.delegate_task_timeout_seconds</code></td><td>Overrides delegated orchestration timeout when set</td></tr>
  </table>

  <h3>Config Search Order</h3>
  <p>Loom looks for configuration in this order:</p>
  <ol style="padding-left: 24px; margin: 12px 0; color: var(--text-dim);">
    <li><code>--config /explicit/path.toml</code> (CLI flag)</li>
    <li><code>./loom.toml</code> (current directory)</li>
    <li><code>~/.loom/loom.toml</code> (home directory)</li>
    <li>Built-in defaults (no models configured)</li>
  </ol>
</section>

<!-- ======================== TROUBLESHOOTING ======================== -->
<section id="troubleshooting">
  <h2>Troubleshooting</h2>

  <details class="accordion">
    <summary>"No models configured"</summary>
    <div class="inner">
      <p>Loom can't find your <code>loom.toml</code>. Place it in the current directory, at <code>~/.loom/loom.toml</code>, or pass it explicitly:</p>
      <pre><code><span class="cmd">loom</span> <span class="flag">--config</span> /path/to/loom.toml serve</code></pre>
    </div>
  </details>

  <details class="accordion">
    <summary>Connection refused to model backend</summary>
    <div class="inner">
      <p>Make sure your model server is running:</p>
      <pre><code><span class="cmt"># Ollama</span>
<span class="cmd">ollama serve</span>
<span class="cmt"># or: systemctl start ollama</span>

<span class="cmt"># LM Studio: Open the app and start the server</span>

<span class="cmt"># Test connectivity:</span>
<span class="cmd">curl</span> http://localhost:11434/api/tags    <span class="cmt"># Ollama</span>
<span class="cmd">curl</span> http://localhost:1234/v1/models     <span class="cmt"># LM Studio</span></code></pre>
    </div>
  </details>

  <details class="accordion">
    <summary>Task fails immediately</summary>
    <div class="inner">
      <p>Check the task details for error information:</p>
      <pre><code><span class="cmd">curl</span> http://localhost:9000/tasks/<span class="str">TASK_ID</span></code></pre>
      <p>Common causes:</p>
      <ul style="padding-left: 20px; color: var(--text-dim);">
        <li>Model returned empty response (try a larger model)</li>
        <li>Workspace path doesn't exist (create it first)</li>
        <li>Model server went down mid-task</li>
      </ul>
      <p>If delegated process runs time out, raise the timeout budget:</p>
      <pre><code><span class="key">[execution]</span>
<span class="key">delegate_task_timeout_seconds</span> = <span class="val">7200</span></code></pre>
      <p>Environment override (optional):</p>
      <pre><code><span class="cmd">export</span> LOOM_DELEGATE_TIMEOUT_SECONDS=7200</code></pre>
    </div>
  </details>

  <details class="accordion">
    <summary>Compactor warnings: <code>output_exceeds_target</code></summary>
    <div class="inner">
      <p>This warning means semantic compaction preserved content but could not reach the exact target size after retry. Loom now keeps that output and logs warning telemetry instead of truncating text.</p>
      <p>In event logs, inspect these fields on compactor validation events:</p>
      <ul style="padding-left: 20px; color: var(--text-dim);">
        <li><code>compactor_warning</code></li>
        <li><code>compactor_warning_reason</code></li>
        <li><code>compactor_warning_delta_chars</code></li>
      </ul>
      <p>If warnings are frequent, increase the relevant runner/compactor limits in <code>loom.toml</code> to reduce pressure.</p>
    </div>
  </details>

  <details class="accordion">
    <summary>Port already in use</summary>
    <div class="inner">
      <pre><code><span class="cmt"># Use a different port</span>
<span class="cmd">loom serve</span> <span class="flag">--port</span> 9001

<span class="cmt"># Or find what's using port 9000</span>
<span class="cmd">lsof</span> <span class="flag">-i</span> :9000</code></pre>
    </div>
  </details>

  <details class="accordion">
    <summary>Tests failing</summary>
    <div class="inner">
      <pre><code><span class="cmt"># Make sure dev dependencies are installed</span>
<span class="cmd">uv sync</span> <span class="flag">--extra</span> dev
<span class="cmt"># or: pip install -e ".[dev]"</span>

<span class="cmt"># Run the full suite</span>
<span class="cmd">pytest</span> <span class="flag">-v</span>

<span class="cmt"># Run a specific test file</span>
<span class="cmd">pytest</span> tests/test_api.py <span class="flag">-v</span></code></pre>
    </div>
  </details>
</section>

</main>

<!-- Navigation active state -->
<script>
  const links = document.querySelectorAll('nav a');
  const sections = document.querySelectorAll('section[id]');

  function setActive() {
    let current = '';
    sections.forEach(s => {
      if (window.scrollY >= s.offsetTop - 100) current = s.id;
    });
    links.forEach(a => {
      a.classList.toggle('active', a.getAttribute('href') === '#' + current);
    });
  }

  window.addEventListener('scroll', setActive);
  setActive();
</script>

</body>
</html>
